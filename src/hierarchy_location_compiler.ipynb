{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and initialized dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define funcions to connect to the db, pass to a pandas df the needed data and save in the db the elabored df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection() -> psycopg2.extensions.connection:\n",
    "    \"\"\"Create and return a database connection\"\"\"\n",
    "    return psycopg2.connect(\n",
    "        dbname = os.getenv('database'),\n",
    "        user =  os.getenv('User'),\n",
    "        password = os.getenv('password'),\n",
    "        host = os.getenv('host'),\n",
    "        port = os.getenv('port')\n",
    "    )\n",
    "\n",
    "def get_connection_string() -> str:\n",
    "    \"\"\"Create a connection string.\"\"\"\n",
    "    return f\"postgresql://{os.getenv('User')}:{ os.getenv('password')}@{os.getenv('host')}:{os.getenv('port')}/{os.getenv('database')}\"\n",
    "\n",
    "def fetch_data_from_db(sql_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from database using SQL file\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    \n",
    "    with open(sql_file, 'r') as file:   # Read the SQL file\n",
    "        sql_query = file.read()\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "    rows = cursor.fetchall()    # Fetch all rows from the executed query\n",
    "    colnames = [desc[0] for desc in cursor.description] # Get column names from the cursor\n",
    "    \n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=colnames) # Create a Pandas DataFrame from the fetched data\n",
    "\n",
    "def save_to_db(df: pd.DataFrame, table_name: str) -> None:\n",
    "    \"\"\"Save dataframe to database\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    \n",
    "    try:\n",
    "        df.to_sql(table_name, get_connection_string(), if_exists='replace', index=False)\n",
    "        print(f\"Data successfully saved to {table_name} table\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to database: {e}\")\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define fuctions to retructure the dataframe (DF) and correctly assign the locations hierarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_geographic_hierarchy(df: pd.DataFrame, searchId: str) -> pd.DataFrame:\n",
    "    # Add columns to the dataframe\n",
    "    df['parent_ID'] = None\n",
    "    df['Latitudine'] = None\n",
    "    df['Longitudine'] = None\n",
    "    \n",
    "    # Create a mapping of province IDs to their numeric codes\n",
    "    province_code_mapping = {}\n",
    "    \n",
    "    # Step 1: Process regions\n",
    "    region_rows = df.loc[(df['id'].str.len() == len(searchId) + 1) & \n",
    "                         (df['id'].str.startswith(searchId))]\n",
    "    \n",
    "    for _, region_row in region_rows.iterrows():\n",
    "        region_id = region_row['id']\n",
    "        \n",
    "        # Step 2: Process provinces\n",
    "        province_rows = df.loc[(df['id'].str.len() == len(region_id) + 1) & \n",
    "                              (df['id'].str.startswith(region_id))]\n",
    "        \n",
    "        for _, province_row in province_rows.iterrows():\n",
    "            province_id = province_row['id']\n",
    "            \n",
    "            # Set parent_ID for province\n",
    "            assign_data(df, df['id'] == province_id, 'id', {\n",
    "                'parent_ID': region_id\n",
    "            })\n",
    "            \n",
    "            # Find a commune that belongs to this province to get its code\n",
    "            province_name = province_row['nome']\n",
    "            sample_communes = df.loc[(df['nome'] == province_name) & \n",
    "                                    (df['id'].str.isdigit()) & \n",
    "                                    (df['id'].str.len() == 6)]\n",
    "            \n",
    "            if not sample_communes.empty:\n",
    "                # Get the first 3 digits of the commune code\n",
    "                province_code = sample_communes.iloc[0]['id'][:3]\n",
    "                province_code_mapping[province_id] = province_code\n",
    "                \n",
    "                # Find all communes with this province code\n",
    "                commune_rows = df.loc[df['id'].str.startswith(province_code) & \n",
    "                                     (df['id'].str.isdigit()) &\n",
    "                                     (df['id'].str.len() == 6)]\n",
    "                \n",
    "                # Set parent_ID for communes\n",
    "                assign_data(df, df['id'].isin(commune_rows['id']), 'id', {\n",
    "                    'parent_ID': province_id\n",
    "                })\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def assign_data(df: pd.DataFrame, filter_condition: bool, id_column: str, columns_to_assign: dict) -> pd.DataFrame:\n",
    "    \"\"\"Helper function to assign data to dataframe rows matching a condition\"\"\"\n",
    "    for col_name, value in columns_to_assign.items():\n",
    "        df.loc[filter_condition, col_name] = value\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to get coordinates for the dim_location table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get coordinates using OpenStreetMap Nominatim API\n",
    "def get_coordinates(comune: str, provincia: str=\"Liguria\", nazione: str=\"Italy\") -> tuple[float, float]:\n",
    "    \"\"\"Get geographic coordinates for a location using Nominatim API\"\"\"\n",
    "    if pd.notna(comune) and comune != \"\":\n",
    "        search_query = f\"{comune}, {provincia}, {nazione}\"  # Format the search query\n",
    "        url = f\"https://nominatim.openstreetmap.org/search?q={search_query}&format=json&limit=1\"\n",
    "        \n",
    "        try:\n",
    "            # Add a delay to respect API rate limits\n",
    "            time.sleep(1)\n",
    "            response = requests.get(url, headers={\"User-Agent\": \"CommuneCoordinatesFinder/1.0\"})\n",
    "            data = response.json()\n",
    "            \n",
    "            if data and len(data) > 0:\n",
    "                return float(data[0]['lat']), float(data[0]['lon'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching coordinates for {comune}: {e}\")\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to add coordinates to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add geographic coordinates to communes in the dataframe\"\"\"\n",
    "    for index, row in df.iterrows():           \n",
    "            # Get coordinates\n",
    "            #print(f\"Getting coordinates for {row['Comune']}\")  # Uncomment to see progress\n",
    "            lat, lon = get_coordinates(row['nome'])\n",
    "            # Update the dataframe\n",
    "            df.at[index, 'Latitudine'] = lat\n",
    "            df.at[index, 'Longitudine'] = lon\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pathSQL_request: str) -> None:\n",
    "    searchId = 'ITC' # Starting search string\n",
    "    df = fetch_data_from_db(pathSQL_request)\n",
    "    df = process_geographic_hierarchy(df,searchId)\n",
    "    \n",
    "    # Print summary\n",
    "    #print(f\"Processed {df['Codice Regione'].notna().sum()} regions\")\n",
    "    #print(f\"Processed {df['Codice Provincia'].notna().sum()} provinces\")\n",
    "    print(f\"Processed {df['parent_ID'].notna().sum()} entry\")\n",
    "    \n",
    "    # Clean up dataframe\n",
    "    df = add_coordinates(df)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Processed {df['Latitudine'].notna().sum()} coordinates\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    #df.to_csv('csv//gerarchia luogo con coordinate.csv', index=False)\n",
    "    #print(\"Coordinates added and saved to 'gerarchia luogo con coordinate.csv'\")\n",
    "        \n",
    "    # Save to database\n",
    "    save_to_db(df, \"gerarchia_luogo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "invalid integer value \"\"5432\"  # Sostituisci con la port del tuo database\" for connection option \"port\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     pathSQL_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect_location_hierarchy.sql\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathSQL_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(pathSQL_request)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(pathSQL_request: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     searchId \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mITC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Starting search string\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data_from_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathSQL_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m process_geographic_hierarchy(df,searchId)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Print summary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#print(f\"Processed {df['Codice Regione'].notna().sum()} regions\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#print(f\"Processed {df['Codice Provincia'].notna().sum()} provinces\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m, in \u001b[0;36mfetch_data_from_db\u001b[1;34m(sql_file)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_data_from_db\u001b[39m(sql_file: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch data from database using SQL file\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mget_db_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sql_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:   \u001b[38;5;66;03m# Read the SQL file\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         sql_query \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mget_db_connection\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_db_connection\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mextensions\u001b[38;5;241m.\u001b[39mconnection:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create and return a database connection\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatabase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: invalid integer value \"\"5432\"  # Sostituisci con la port del tuo database\" for connection option \"port\"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pathSQL_request = 'select_location_hierarchy.sql'\n",
    "    main(pathSQL_request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
